{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from optim import Adam\n",
    "from rnn import RNN, rnn_training_step, sample, init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "with open('data/input.txt') as fp:\n",
    "    data_loader = DataLoader(fp.read(), batch_size=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nnden;:ibt 3n:o:'vj?tb-lgp\n",
      "sai&3 $nd-ivn-:ztm.x.;3ih zcd&ahb h\n",
      "$:dle:.fd, yl..fe'ri.or,l.ubypqw&y?q:ps.b!g!!li$,q3nrpxs'ce,ko-.:?l'eqoplvcvcs;'vm,mvcbjj&zac;uhzqxd:sqzaf!k&cfju,\n",
      "nq,p3lpr$$.dlk.gr!-hnd\n",
      "\n",
      "iteration: 0, loss: 3.6634675465625888\n",
      "\n",
      " of whem aint fok of haw,\n",
      "and stil?\n",
      ":\n",
      "bece for make fin is you thels nob, with to netelind 't in my liste.\n",
      "\n",
      "satitess'd.\n",
      "\n",
      "by ard noml,\n",
      "by makinof whe pikent int hather then andinnd gishisethatcand your\n",
      "\n",
      "iteration: 10000, loss: 2.16412378537847\n",
      "\n",
      "?\n",
      "\n",
      "jurece will:\n",
      "butthot streich it hat with\n",
      "stermed, there of sa cauls:\n",
      "wold atap cow a tecplioft'me she same'st whastewile iner mysenpoust sinere.\n",
      "\n",
      "durso!\n",
      "\n",
      "rupfow!--ofe.\n",
      "\n",
      "rumes!\n",
      "\n",
      "nomeas sattn my is.\n",
      "\n",
      "\n",
      "iteration: 20000, loss: 1.7250549474268468\n",
      "\n",
      "s:\n",
      "and will to truck bit with that intast forchmand-sight oon,\n",
      "you hend canderve, that that' home i isien, heme? whing his measingn whis is his kintse with thou notwacay youn:\n",
      "near'd than it,\n",
      "'tes:\n",
      "th\n",
      "\n",
      "iteration: 30000, loss: 1.9739785540711368\n",
      "\n",
      "s him sea! these office,,\n",
      "a potined i were\n",
      "i am wind; you histe midction own a good dume of a dis;\n",
      "and wi have is norfuce in fairs, sir the no traniio.\n",
      "\n",
      "pround,\n",
      "my gord pare anely anure you, willded b\n",
      "\n",
      "iteration: 40000, loss: 1.6283977646835803\n",
      "\n",
      "u kears reaks so, heart for resentess.\n",
      "\n",
      "secons as haliout if\n",
      "you hasters? sen here i is a ible; to tonguses mine your perill you say, oe that to the westriess, for uneran mone't?\n",
      "\n",
      "frow beor hat some a\n",
      "\n",
      "iteration: 50000, loss: 1.418932157230682\n",
      "\n",
      "renous lay,\n",
      "we all jedesuns fasce,\n",
      "scuthing to trelet tringether\n",
      "have-offe is yetrembsed, my heagntsies faie of bolingbroke:\n",
      "well the eall pold thoughby gloon hore redoll.\n",
      "\n",
      "core,\n",
      "and your dawery? thou\n",
      "\n",
      "iteration: 60000, loss: 1.022302794570002\n",
      "\n",
      "rucede.\n",
      "what hath tisty pune tire plonger as were ward ancee,\n",
      "chay dead.\n",
      "\n",
      "dewars:\n",
      "his leint-com the hearts of that us is lainy so;\n",
      "and his like in the cooth:' thou no thou asw befores, armow he shiek \n",
      "\n",
      "iteration: 70000, loss: 1.7438153023441998\n",
      "\n",
      "osaliest by they servence would him a god his fair to that\n",
      "with becation:\n",
      "pierune's;\n",
      "go your fall\n",
      "wath threveng a dither, giveded have for law\n",
      "'o beathes resper's so must that deave youn hir the turno\n",
      "\n",
      "iteration: 80000, loss: 1.2494755774228727\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "num_epochs = 2\n",
    "sample_every = 10000\n",
    "sample_size = 200\n",
    "print_every = 10000\n",
    "\n",
    "rnn = RNN()\n",
    "params = init_params(data_loader.vocab_size, hidden_size=hidden_size)\n",
    "optimizer = Adam(params)\n",
    "it = 0\n",
    "for epoch in range(num_epochs):\n",
    "    hidden_state = np.zeros((1, hidden_size))\n",
    "    for x, y in data_loader:\n",
    "        if it % sample_every == 0:\n",
    "            one_hot = sample(rnn, hidden_state, x[0], params, sample_size)\n",
    "            generated_text = data_loader.decode(one_hot)\n",
    "            print()\n",
    "            print(generated_text)\n",
    "            print()\n",
    "        loss, hidden_state, dparams = rnn_training_step(rnn, hidden_state, x, y, params)\n",
    "        if it % print_every == 0:\n",
    "            print('iteration: {}, loss: {}'.format(it, loss))\n",
    "        optimizer.step(dparams)\n",
    "        it += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
